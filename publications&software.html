<!DOCTYPE HTML>

<html>
	<head>
		<title>SDC Lab</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">
					<!-- Logo -->
						<img src="images/isail_logo.png" alt="" /><span><h2>Welcome to <a href="index.html" id="logo">SDC</a> Lab !</h2></span>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li ><a href="index.html">Home</a></li>
								<li><a href="people.html">People</a></li>
								<li class="current"><a href="publications&software.html">Publications</a></li>
								<li><a href="teaching.html">Teaching</a></li>
							</ul>
						</nav>

				</div>
			<!-- Banner -->
				<section id="banner">
					<header>
						<h2>Welcome to SDC Lab!</h2>
						<a href="#" class="button">Learn More</a>
					</header>
				</section>
				<section class="wrapper style1">
					<div class="container">
						<div id="content">

							<!-- Content -->

								<article>

									
									<header>
										<h2>Journal</h2>
									</header>
									<ul style="list-style-type:disc;">
										<li style="text-align: justify;">[1]	<b>J. Duan</b>, W. Cao, Y. Zheng, and L. Zhao, <a href="https://ieeexplore.ieee.org/abstract/document/10124022">“On the Optimization Landscape of Dynamic Output Feedback Linear Quadratic Control,”</a> pp. 1–16, Jan. 2023. &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2201.09598">Download</a></li>
										<li style="text-align: justify;">[2]	 G. Ren, G. Zhan, L. Tang, S. E. Li, J. Jiang, K. Li, and <b>J. Duan</b>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0968090X2300150X">“Improve generalization of driving policy at signalized intersections with adversarial learning,”</a> vol. 152, pp. 104161–104161, Jul. 2023.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2204.04403">Download</a></li>
										<li style="text-align: justify;">[3]	W. Wang, Y. Zhang, J. Gao, Y. Jiang, Y. Yang, Z. Zheng, W. Zou, J. Li, C. Zhang, W. Cao, G. Xie, <b>J. Duan</b>, S. E. Li, <a href="https://www.sciencedirect.com/science/article/pii/S2772424723000070">“GOPS: A general optimal control problem solver for autonomous driving and industrial control applications,”</a> Communications in Transportation Research, vol. 3, p. 100096, Dec. 2023.</li>
										<li style="text-align: justify;">[4]	J. Li, S. E. Li, <b>J. Duan</b>, Y. Lyu, W. Zou, Y. Guan, Y. Yin, <a href="https://ieeexplore.ieee.org/abstract/document/10098871">“Relaxed Policy Iteration Algorithm for Nonlinear Zero-Sum Games with Application to H-infinity Control,”</a> pp. 1–8, Jan. 2023.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10098871">Download</a></li>
										<li style="text-align: justify;">[5]	<b>J. Duan</b>, J. Li, Q. Ge, S. E. Li, M. Bujarbaruah, F. Ma, D. Zhang, <a href="https://ieeexplore.ieee.org/abstract/document/10065554">“Relaxed Actor-Critic With Convergence Guarantees for Continuous-Time Optimal Control of Nonlinear Systems,”</a> vol. 8, no. 5, pp. 3299–3311, May 2023.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/1909.05402">Download</a></li>
										<li style="text-align: justify;">[6]	Y. Ren, J. Jiang, G. Zhan, S. E. Li, C. Chen, K. Li, <b>J. Duan</b>, <a href ="https://ieeexplore.ieee.org/abstract/document/9857655">“Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections,”</a> IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 12, pp. 24145–24156, Nov. 2021.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2110.12359">Download</a></li>
										<li style="text-align: justify;">[7]	Y. Guan, Y. Ren, Q. Sun, S. E. Li, H. Ma, <b>J. Duan</b>, Y. Dai, B. Cheng, <a href="https://ieeexplore.ieee.org/abstract/document/9760270">“Integrated Decision and Control: Toward Interpretable and Computationally Efficient Driving Intelligence,”</a> IEEE Transactions on Cybernetics, pp. 1–15, 2022.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2103.10290">Download</a></li>
										<li style="text-align: justify;">[8]	B. Peng, <b>J. Duan</b> et al., <a href="https://ieeexplore.ieee.org/abstract/document/9785377">“Model-Based Chance-Constrained Reinforcement Learning via Separated Proportional-Integral Lagrangian,”</a> pp. 1–13, Jan. 2022.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2108.11623">Download</a></li>
										<li style="text-align: justify;">[9]	Z. Liu*, <b>J. Duan*</b>, W. Wang, S. E. Li, Y. Yin, Z. Lin, B. Cheng, <a href="https://ieeexplore.ieee.org/abstract/document/9724145">“Recurrent Model Predictive Control: Learning an Explicit Recurrent Controller for Nonlinear Systems,”</a> vol. 69, no. 10, pp. 10437–10446, Oct. 2022.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2102.10289">Download</a></li>
										<li style="text-align: justify;">[10]	<b>J. Duan</b>, Z. Liu, Shengbo Eben Li, F. B. Hu, Z. Jia, and B. Cheng, <a href ="https://www.sciencedirect.com/science/article/pii/S0925231221015848">“Adaptive dynamic programming for nonaffine nonlinear optimal control problem with state constraints,”</a> vol. 484, pp. 128–141, May 2022.‌&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/1911.11397">Download</a></li>
										<li style="text-align: justify;">[11]	<b>J. Duan</b> et al., <a href ="https://ieeexplore.ieee.org/abstract/document/9662668">“Fixed-Dimensional and Permutation Invariant State Representation of Autonomous Driving,”</a> IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 7, pp. 9518–9528, Jul. 2022.‌&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2105.11299">Download</a></li>
										<li style="text-align: justify;">[12]	<b>J. Duan</b>, Y. Guan, S. E. Li, Y. Ren, Q. Sun, and B. Cheng, <a href="https://ieeexplore.ieee.org/abstract/document/9448360">“Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for Addressing Value Estimation Errors,”</a> IEEE Transactions on Neural Networks and Learning Systems, pp. 1–15, 2021.‌&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2001.02811">Download</a></li>
										<li style="text-align: justify;">[13]	Y. Guan, S. E. Li, <b>J. Duan</b>, J. Li, Y. Ren, Q. Sun, B. Cheng, <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/int.22466">“Direct and indirect reinforcement learning,”</a> International Journal of Intelligent Systems, vol. 36, no. 8, pp. 4439–4467, May 2021.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/1912.10600">Download</a></li>
										<li style="text-align: justify;">[14]	<b>J. Duan</b>, S. Li, Y. Guan, Q. Sun, and B. Cheng, <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2019.0317">“Hierarchical Reinforcement Learning for Self-Driving Decision-Making without Reliance on Labeled Driving Data,”</a> IET Intelligent Transport Systems, Jan. 2020.‌&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2001.09816">Download</a></li>
										<li style="text-align: justify;">[15]	L. Hou*, <b>J. Duan*</b>, W. Wang, R. Li, G. Li, B. Cheng, <a href="https://www.hindawi.com/journals/jat/2019/4023970/">“Drivers’ Braking Behaviors in Different Motion Patterns of Vehicle-Bicycle Conflicts,”</a> vol. 2019, pp. 1–17, Mar. 2019.</li>
										<li style="text-align: justify;">[16]	李升波, 关阳, 侯廉, 高洪波, <b>段京良</b>, 梁爽, 汪玉, 成波, 李克强, 任伟，李骏. <a href="https://www.cnki.com.cn/Article/CJFDTotal-QCAN201902001.htm">“深度神经网络的关键技术及其在自动驾驶领域的应用,”</a>  汽车安全与节能学报, vol. 10, no. 2, pp. 119-145, 2019.</li>
										<li style="text-align: justify;">[17]	<b>J. Duan</b> et al., <a href="https://www.sciencedirect.com/science/article/pii/S0001457517303019">“Driver braking behavior analysis to improve autonomous emergency braking systems in typical Chinese vehicle-bicycle conflicts,”</a> vol. 108, pp. 74–82, Nov. 2017.</li>
									</ul>


									<header>
										<h2>Conference Papers</h2>
									</header>							
									<ul style="list-style-type:disc;">
									    <li style="text-align: justify;">[1] <b>J. Duan</b>, J. Li, Z. Lin, <a href="https://ieeexplore.ieee.org/abstract/document/9867384">“Optimization Landscape of Gradient Descent for Discrete-time Static Output Feedback,”</a> 2022 American Control Conference (ACC), Atlanta, Georgia, USA, 2022.&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2109.13132">Download</a></li>
									    <li style="text-align: justify;">[2] <b>J. Duan</b>, F. Zhang, S. E. Li, Y. Ren, B. Cheng, Z. Xin, <a href="https://ieeexplore.ieee.org/abstract/document/9790288">“Applications of Distributional Soft Actor-Critic in Real-world Autonomous Driving,”</a> 2022 IEEE International Conference on Computer, Control and Robotics (ICCCR), Shanghai, China, 2022.</li>
									    <li style="text-align: justify;">[3] W. Cao, J. Chen, <b>J. Duan</b>,  S. E. Li, Y. Lyu, Z. Gu, Y. Zhang, <a href="https://www.sciencedirect.com/science/article/pii/S240589632102245X">“Reinforced Optimal Estimator,”</a> 2021 Modeling, Estimation and Control Conference (MECC), Austin, Texas, USA, 2021, pp. 366-373.&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://people.iiis.tsinghua.edu.cn/~jychen/publication/2021/mecc2021wenhan/MECC2021Wenhan.pdf">Download</a></li>
									    <li style="text-align: justify;">[4] Z. Gu, Y. Yang, <b>J. Duan</b>,  S. E. Li, J. Chen, W. Cao, S. Zheng, <a href="https://ieeexplore.ieee.org/abstract/document/9564576">“Belief State Separated Reinforcement Learning for Autonomous Vehicle Decision Making under Uncertainty,”</a> 2021 IEEE International Conference on Intelligent Transportation Systems (ITSC), Indianapolis, IN, USA, 2021, pp. 586-592.&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://idlabweb.oss-cn-beijing.aliyuncs.com/a231dafd2420ebca8f7f2c5ca9a54c3c.pdf">Download</a></li>
									    <li style="text-align: justify;">[5] B. Peng, Y. Mu, <b>J. Duan</b>, Y. Guan,  S. E. Li, J. Chen, <a href="https://ieeexplore.ieee.org/abstract/document/9575205">“Separated Proportional-Integral Lagrangian for Chance Constrained Reinforcement Learning,”</a> 2021 IEEE Intelligent Vehicle Symposium (IV), Nagoya University, Nagoya, Japan, 2021. (Best Student Paper Award finalist)&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2102.08539">Download</a></li>
									    <li style="text-align: justify;">[6] Z. Lin*, <b>J. Duan*</b>, S. E. Li, J. Li, H. Ma, Q. Sun, J. Chen, B. Cheng, <a href="https://ieeexplore.ieee.org/abstract/document/9349412">“Solving Finite-horizon HJB for Optimal Control of Continuous-time Systems,”</a> 2021 IEEE International Conference on Computer, Control and Robotics (ICCCR), Shanghai, Beijing, 2021. (* equal contributors)</li>
									    <li style="text-align: justify;">[7] Y. Ren*, <b>J. Duan*</b>, S. E. Li, Y. Guan, Q. Sun, <a href="https://ieeexplore.ieee.org/abstract/document/9294300">“Improving Generalization of Reinforcement Learning with Minimax Distributional Soft Actor-critic,”</a> 2020 IEEE International Conference on Intelligent Transportation Systems (ITSC), Rhodes, Greece, 2020, pp. 1-6. (* equal contributors, Best Student Paper Award)&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2002.05502">Download</a></li>
									    <li style="text-align: justify;">[8] L. Wen*, <b>J. Duan*</b>, S. E. Li, et al., <a href="https://ieeexplore.ieee.org/abstract/document/9294262">“Safe reinforcement learning for autonomous vehicles through parallel constrained policy optimization,”</a> 2020 IEEE International Conference on Intelligent Transportation Systems (ITSC), Rhodes, Greece, 2020. (* equal contributors)&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2003.01303">Download</a></li>
									    <li style="text-align: justify;">[9] Z. Lin*, <b>J. Duan*</b>, S. E. Li, et al., <a href="https://ieeexplore.ieee.org/abstract/document/9274944">“Continuous-time Finite-horizon ADP for Automated Vehicle Controller Design with High Efficiency,”</a> 2020 IEEE International Conference on Unmanned Systems (ICUS), Harbin, China, 2020, 978-984. (* equal contributors, Best Paper Award)&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2007.02070">Download</a></li>
									    <li style="text-align: justify;">[10] <b>J. Duan</b>, S. E. Li, B. Cheng, et al., <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-its.2019.0317">“Hierarchical Reinforcement Learning for Decision Making of Self-Driving Cars without Reliance on Labeled Driving Data.,”</a> 14th International Symposium on Advanced Vehicle Control, AVEC'18, Beijing, China, July 16-20, 2018, pp. 1-7. (Best Paper Award finalist)&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2001.09816">Download</a></li>
									</ul>
									
									<header>
										<h2>Book Chapter</h2>
									</header>
									<ul style="list-style-type:disc;">
										<li style="text-align: justify;">[1]	S. E. Li, L. Xin, C. Liu, <b>J. Duan</b>, and S. E. Li, <a href="https://digital-library.theiet.org/content/books/10.1049/pbtr025e_ch23">“Promoting connected and automated vehicles with cooperative sensing and control technology,”</a> pp. 515–531, Sep. 2019, doi: https://doi.org/10.1049/pbtr025e_ch23. Chapter 23 in book: Cooperative Intelligent Transport Systems: Towards high-level automated driving, pp. 515-528, 2019, IET.</li>
										<li style="text-align: justify;">[2] J. Chen, <b>J. Duan</b>, Y. Guan, Q. Sun, Y. Yin, and S. E. Li,  <a href="https://digital-library.theiet.org/content/books/10.1049/pbtr025e_ch23">“Self-learning Decision and Control for Highly Automated Vehicles,”</a> Chapter 10 in book: AI-enabled Technologies for Autonomous and Connected Vehicles, pp. 307–330, Sep. 2022, doi: https://doi.org/10.1007/978-3-031-06780-8_11. ‌&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://arxiv.org/abs/2109.13132">Download</a></li>
									</ul>

									<header>
										<h2>ArXiv Papers</h2>
									</header>							
									<ul style="list-style-type:disc;">
										<!-- <li>[C1] J. Duan, J. Li, Z. Lin, “Optimization Landscape of Gradient Descent for Discrete-time Static Output Feedback,” 2022 American Control Conference (ACC), Atlanta, Georgia, USA, 2022.										 -->
									</ul>


								</article>

						</div>
					</div>
				</section>
	
			<!-- Footer -->
				<div id="footer">
					<div class="container">
						<div class="row">
							<section class="col-6-mobile">
								<h3>Contact us</h3>
								<form>
									<ul style="list-style-type:disc;">
									    <p><b>email</b>: <a href="mailto:duanjl15@163.com">duanjl15@163.com</a></p>
										<p><b>Location</b>: <a href="https://ditu.amap.com/search?id=B000AB9ACT&city=110108&geoobj=139.688386%7C35.672721%7C139.713877%7C35.685061&query_type=IDQ&query=%E5%8C%97%E4%BA%AC%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%9C%9F%E6%9C%A8%E7%8E%AF%E5%A2%83%E6%A5%BC&zoom=15.82">1012, Civil and Environmental Building, University of Science and Technology Beijing, No. 30 College Road, Haidian District, Beijing, China</a></p>								
									</ul>
								</form>
							</section>
						</div>
					</div>

					<!-- Icons -->
						<ul class="icons">
							<!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li> -->
							<li><a href=" https://github.com/SDC-laboratory" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<!-- <li><a href="#" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							<li><a href="#" class="icon brands fa-google-plus-g"><span class="label">Google+</span></a></li> -->
						</ul>

					<!-- Copyright -->
						<div class="copyright">
							<ul class="menu">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>

				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
